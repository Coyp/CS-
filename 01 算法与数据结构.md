# 图
## 表示方法
### 邻接矩阵
```c
vector<vector<int>> grap;
```
### 邻接链表
```c
map<string, multiset<string>> grap;
map<string, list<string>> grap;
```
## 图算法
### DFS
1.非递归  
使用stack  
2.递归  
```c
void dfs(map<string, multiset<string>>& grap, string &currNode)
{
    while (!grap[currNode].empty())
    {
        string nextNode = *grap[currNode].begin();
        grap[currNode].earse(grap[currNode].begin());
        dfs(grap, nextNode);
    }
    
    res.push_back(currNode);
}

void dfs(vector<vector<int>>& grap, vector<vector<int>>& visted, int from)
{
    for (int i = from; i < n; i++)
    {
        for (int j = 0; j < n; j++)
        {
            if (grap[i][j] && visted[i][j] == false)
            {
                visted[i][j] = true;
                dfs();
            }
        }
    }
}
```
### BFS
1.非递归  
使用队列  

### A*

### Dijkstra
使用最小堆  

## 图计算
### 基础数据结构
G = (V, E, D) (vertex\ edge\ data)  


# 大数据
https://blog.csdn.net/v_july_v/article/details/7382693  
https://wizardforcel.gitbooks.io/the-art-of-programming-by-july/content/06.02.html  
## 分而治之/hash映射 + hash统计 + 堆/快速/归并排序
1）分而治之/hash映射：数据太大，内存受限时，将大文件化成（取模映射）小文件
2）hash_map统计：当大文件转化为小文件，使用hash_map(key, value)来进行统计   
3）堆/快排：统计完后，进行排序获取  
### 例1.海量日志数据，提取出某日访问百度次数最多的IP  
坑：  
1）ip地址有32位，总共有2^32=32亿（10^8）的IP数量，若创建一个数组去统计数量，2^32 * 4 = 16GB, 32位的内存空间也即4GB，内存中放不下，因此要分开  
算法：
1）分而治之/hash映射：数据太大，内存受限时，将大文件化成（取模映射）小文件 —— 映射成1000个小文件  
2）hash_map统计：当大文件转化为小文件，使用hash_map(ip, value)来进行统计 —— 分别统计出1000个小文件的最频繁IP地址  
3）堆/快排：统计完后，进行排序获取  
### 例2.寻找热门查询，300万个查询字符串中统计最热门的10个查询
坑：  
1）在于单位的换算  
```c
300万 * 255B = 300 * 10^4 * 2^8 B = 300 * 5*2 * 5*2 * 5*2 * 10 * 2^8 = 300 * 125 * 2^11 * 10 = 3000 * 2^18B = 3000 * 2^20 /4 B = 0.75GB  100万 = 1000 * 2^10 = 2 ^ 20  
```
算法：  
1）由上分析可以知道能够一次放入内存中，那么可以通过hashmap统计字符串数量  
2）根据寻找最大的第k个数的方法（堆排序最小堆priority_queue或者快排分半）  
### 例3.有一个1GB的文件，里面每一行都是一个词，词的大小不超过16字节，内存限制大小是1MB，返回频率最高的100个词
坑：  
1）仍然是内存的限制
