
# 大数据

<https://blog.csdn.net/v_july_v/article/details/7382693>
<https://wizardforcel.gitbooks.io/the-art-of-programming-by-july/content/06.02.html>

## 分而治之/hash映射 + hash统计 + 堆/快速/归并排序
1）分而治之/hash映射：数据太大，内存受限时，将大文件化成（取模映射）小文件 —— 类似于分布式中用一致哈希将数据分开  
2）hash_map统计：当大文件转化为小文件，使用hash_map(key, value)来进行统计   
3）堆/快排：统计完后，进行排序获取  
### 例1.海量日志数据，提取出某日访问百度次数最多的IP  
坑：  
1）ip地址有32位，总共有2^32=32亿（10^8）的IP数量，若创建一个数组去统计数量，2^32 * 4 = 16GB, 32位的内存空间也即4GB，内存中放不下，因此要分开  
算法：
1）分而治之/hash映射：hash(ip)%1000 映射成1000个小文件    
2）hash_map统计：当大文件转化为小文件，使用hash_map(ip, value)来进行统计 —— 分别统计出1000个小文件的最频繁IP地址  
3）堆/快排：统计完后，进行排序获取  
### 例2.寻找热门查询，300万个查询字符串中统计最热门的10个查询
坑：  
1）在于单位的换算  
```c
300万 * 255B = 300 * 10^4 * 2^8 B = 300 * 5*2 * 5*2 * 5*2 * 10 * 2^8 = 300 * 125 * 2^11 * 10 = 3000 * 2^18B = 3000 * 2^20 /4 B = 0.75GB 
100万 = 1000 * 2^10 = 2 ^ 20  = 1MB  
10亿 = 1GB  
```
算法：  
1）由上分析可以知道能够一次放入内存中，那么可以通过hashmap统计字符串数量  
2）根据寻找最大的第k个数的方法（堆排序最小堆priority_queue或者快排分半）  
### 例3.有一个1GB的文件，里面每一行都是一个词，词的大小不超过16字节，内存限制大小是1MB，返回频率最高的100个词
坑：  
1）仍然是内存的限制  
### 例4.海量数据分布在100台电脑中，想办法高效统计出这批数据的TOP10 
1.分别在每台电脑上使用堆求最大的10个数，然后将100台电脑的合并  
若同一种元素会在不同机器上同时出现，那么应该将所有的数据都读取一遍后重新hash  
### 例5.有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复，按照query的频度排序
1.由于是重复的，所有将所有文件都读一遍重新hash分成10个文件，再进行统计和排序  
### 例5.给定a,b两个文件，各存放50亿个url，每个url占64字节，内存限制为4G，找出a和b共同的url
1）10亿（billion） = 1GB  
### 例6.100万个数中找出最大的100个数
快排：O(n)
堆：O(nlogK)  

## 多层划分
数据范围很大，不能直接利用hash表，需通过多次划分，逐步确定范围  
### 例1. 2.5亿个整数中找出不重复的整数个数，内存空间不足以容纳2.5亿个数
也是分啊，分成64个文件，然后再分别统计  
### 例2. 5亿个int找中位数  
方法1：  
根据每个整数的前5位可以划分出32个桶，且每个桶是排好序的，00000 < 00001 此时还知道每个桶中数字的数量，就可以判断中位数在哪个桶中  
方法2：
每次向内存加载1G的数字，比较第32位，0分在一个文件，1分在一个文件，此时1中都是负数，0中都是正数，比较两个文件的大小，看中位数在哪个文件中，丢弃其他的文件，并继续比较第31位  

## Bloom filter / Bitmap